"""
## VRP Solution Parameters and Error Gap Statistics

This script handles the computation and analysis of VRP (Vehicle Routing Problem) solutions.
It includes functions to generate result data, transform data, and perform descriptive statistics
over multiple seeds. The results are saved to a dataframe which is built in a custom transformation process from CSV files generated by pyVRP statistics. This is used to plot said data (yet to be implemented as a function) and generate insights in the form of a channel including all of the mentioned statisctics along the solution's computing time.

## Functions
- generate_resultdata(csv_filepath, bks): Generate result data for a given VRP instance.
- transform_data(csv_file_path, bks): Transform raw data into a structured DataFrame.
- concatenate_dataframes(df_list): Concatenate a list of DataFrames.
- df_stats_average(df, num_seeds): Calculate average statistics over multiple seeds.
- df_stats_minimize(df, num_seeds): Calculate minimized statistics over multiple seeds.
- merge_df_stats_maximize(df, num_seeds): Merge DataFrames and calculate maximized statistics.
"""

import logging
import os
#import pickle as pkl#from core.vrp import VRP_OBJECT
import matplotlib.pyplot as plt
#import matplotlib.scale
from matplotlib.ticker import LogLocator, LogFormatter
import pandas as pd
from core.vrp import VRP_OBJECT
from core.evaluation import VRP_SOLUTION
from core.utils import set_file_directory
import math

import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)

### Computation

def generate_resultdata(filepath: str, bks: float) -> tuple:
    """
    Generate result data for a given VRP instance.

    **Parameters:**
    - `file_path (str)` Path to the CSV file containing raw data.
    - `bks (float)` Best known solution value.

    **Returns:**
    - `pd.DataFrame` A DataFrame containing the transformed data for a singular seed.
    """

    # test data filepaths

    path_to_load_sing_hvrptw_pkl = os.path.join(os.getcwd(), filepath)

    path_to_write_sing_sol_pkl = os.path.join(os.getcwd(), "test_output")

    # logger minimal setup

    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(message)s",
        handlers=[
            logging.FileHandler(os.path.join(os.getcwd(), "testlog/test.log"), mode="w"),
            logging.StreamHandler(),
        ],
    )
    logger = logging.getLogger()

    # solver params

    seeds = [1, 2, 3, 4, 5]
    global stop_criterion_value

    solver_hyper_params = {
        "solver": "pyvrp",
        "stop_criterion": "runtime",
        "stop_criterion_value": stop_criterion_value,
        "multiplier": 100,
        "seed": -1,
    }

    ## load instance and generate solution for vrp

    transformed_df_list_over_seeds = []

    # perform single run and subsequently export stats to csv
    for seed in seeds:
        solver_hyper_params["seed"] = seed
        print(seed)

        instance = VRP_OBJECT(name="", type="HVRPTW").load_instance(os.path.join(path_to_load_sing_hvrptw_pkl), read_pkl=True)
        route_dict, runtime, result_raw = instance.solve(solver_hyper_params)
        instance_sol = VRP_SOLUTION(instance, solver_hyper_params, runtime, route_dict)
        instance_sol.write_to_pkl(path_to_write_sing_sol_pkl)

        logger.info(f"Run completed in {runtime} sec.")
        logger.info("done")

        # csv for multiple seeds

        csv_file_path = os.path.join(path_to_write_sing_sol_stats, f"stats_seed{seed}.csv")
        result_raw.stats.to_csv(csv_file_path)

        # call function to transform data

        df_transformed_data = transform_data(csv_file_path, bks)
        transformed_df_list_over_seeds.append(df_transformed_data)

    # concatenate dataframes over seeds

    prefinal_df = concatenate_dataframes(transformed_df_list_over_seeds)

    # perform descriptive statistics over seeds

    number_of_seeds = len(seeds)

    final_df_m = df_stats_average(prefinal_df, number_of_seeds)
    final_df_mm = df_stats_minimize(final_df_m, number_of_seeds)
    final_df_mmm = merge_df_stats_maximize(final_df_mm, number_of_seeds)

    # split filename to get instance name (fleet composition) for plot label

    instance_split_filename = filepath.split("/", 1)
    graph_label = instance_split_filename[1] # + " " + "$\it {} $".format(descriptive_type)

    print(final_df_mmm)
    return final_df_mmm, graph_label


### Transformation

# function to transform data (cumulative runtime, error gap)

def transform_data(csv_file_path: str, bks: float) -> pd.DataFrame:
    '''
    Transform data from csv file to a DataFrame with columns for cumulative runtime, error gap, and relative runtime.
    
    **Parameters:**
    - `csv_file_path (str)` Path to the CSV file containing raw data.
    - `bks (float)` Best known solution value.

    **Returns:**
    - `pd.DataFrame` A DataFrame containing the transformed data for a singular seed.
    '''
    
    df = pd.read_csv(csv_file_path, usecols=["runtime", "feas_best_cost"])

    print(df.columns)
    print(df)

    ## standardize checkpoint runtime to 0.06 sec

    # cumulate runtime of individual iterations up to the nearest 0.06 sec and store incremental index as new column

    df["cumulative_runtime"] = 0
    df["cumulative_runtime"] = df["runtime"].cumsum()
    df["cumulative_runtime"] = df["cumulative_runtime"].apply(lambda x: math.floor(x / 0.12) * 0.12) # gaussian floor function to ensure that checkpoints are always concluding a 0.06 sec interval (a)
    print(df)

    df = df.groupby("cumulative_runtime").agg({"feas_best_cost": "min"}).reset_index() # for checkpointing, take the minimum feasible cost of all iterations within the same checkpoint (b)

    print(df)

    # drop duplicates (if any)

    df = df.drop_duplicates(subset="cumulative_runtime", keep="first") # check if last - resolved, see a & b

    # error gap in percent

    df["error_gap"] = ((df["feas_best_cost"] / 100) - bks) / bks * 100  # account for floating point standard (requiring division by the same factor used as solver param)

    # relative runtime (cumulative in percent)

    highest_index = df.index.max()
    df["relative_runtime_checkpoints"] = (df.index / highest_index) * 100.0

    df.to_csv(os.path.join(path_to_write_sing_sol_stats, "stats_singlerun_edited.csv"))
    print(df)
    return df
    
def concatenate_dataframes(dataframes: list) -> pd.DataFrame:
    '''
    Concatenate multiple DataFrames from singular seeds into a single DataFrame. 
    
    **Parameters:**
    - `df_list (list)` A list of DataFrames containing the transformed data for each seed.
    
    **Returns:**
    - `pd.DataFrame` A single DataFrame containing the concatenated data from all seeds.
    '''

    # rename columns previnting duplicate labels from causing ambiguity

    for i, df in enumerate(dataframes):
        df.rename(columns={'cumulative_runtime': f'cumulative_runtime_df{i+1}'}, inplace=True)
        df.rename(columns={'feas_best_cost': f'feas_best_cost_df{i+1}'}, inplace=True)
        df.rename(columns={'error_gap': f'error_gap_df{i+1}'}, inplace=True)
        df.rename(columns={'relative_runtime_checkpoints': f'relative_runtime_checkpoints_df{i+1}'}, inplace=True)
    
    # concatenate dataframes so that tupels (a, b) and (a, b) become (a, b, a, b)

    df_concatenated = pd.concat(dataframes, axis=1, join="inner") # inner join to ensure that only indices present in all dataframes are considered, axis=1 to concatenate horizontally (column-wise)
    print(df_concatenated)

    return df_concatenated

def df_stats_average(prefinal_df: pd.DataFrame, number_of_seeds: int) -> pd.DataFrame:
    '''
    A descriptive statistical value. Compute the average error gap for a given DataFrame along its computation.
    
   **Parameters:**
    - `prefinal_df (DataFrame)` A DataFrame containing the transformed data for all seeds.
    - `number_of_seeds (int)` The number of seeds used to generate the data. Needed to determine the number of columns to consider to compute arithmetic mean.
    
    **Returns:**
    - `DataFrame` A DataFrame containing the average error gap for each checkpoint.
    '''
    
    # prepare list of columns for later use
     
    # seeds_per_observation = len(prefinal_df.columns) / 4 # 4 columns per seed (cumulative_runtime, feas_best_cost, error_gap, relative_runtime_checkpoints)
    error_gap_list = [f"error_gap_df{i+1}" for i in range(int(number_of_seeds))] # list of error gap columns 

    print(number_of_seeds)
    
    # create new column and store average error from different columns with the same index
    
    prefinal_df["error_gap_stat_avg"] = prefinal_df[error_gap_list].mean(axis=1)

    return prefinal_df

def df_stats_minimize(prefinal_df: pd.DataFrame, number_of_seeds: int) -> pd.DataFrame:
    '''
    A descriptive statistical value. Compute the minimum error gap for a given DataFrame along its computation time.
    
    **Parameters:**
    - `prefinal_df (DataFrame)` A DataFrame containing the transformed data for all seeds.
    - `number_of_seeds (int)` The number of seeds used to generate the data.
    
    **Returns:**
    - `DataFrame` A DataFrame containing the minimum error gap for each checkpoint.
    '''
    
    # prepare list of columns for later use
    
    # seeds_per_observation = len(prefinal_df.columns) / 4 # 4 columns per seed (cumulative_runtime, feas_best_cost, error_gap, relative_runtime_checkpoints)
    error_gap_list = [f"error_gap_df{i+1}" for i in range(int(number_of_seeds))] # list of error gap columns
    print(number_of_seeds)
    
    # create new column and store average error from different columns with the same index
    
    prefinal_df["error_gap_stat_min"] = prefinal_df[error_gap_list].min(axis=1)

    return prefinal_df

def merge_df_stats_maximize(prefinal_df: pd.DataFrame, number_of_seeds:int) -> pd.DataFrame:
    '''
    A descriptive statistical value. Compute the maximum error gap for a given DataFrame along its computation time.
    
    **Parameters:**
    - `prefinal_df (DataFrame)` A DataFrame containing the transformed data for all seeds.
    - `number_of_seeds (int)` The number of seeds used to generate the data.
    
    **Returns:**
    - `DataFrame` A DataFrame containing the maximum error gap for each checkpoint.
    '''
    
    # prepare list of columns for later use
    
    # seeds_per_observation = len(prefinal_df.columns) / 4 # 4 columns per seed (cumulative_runtime, feas_best_cost, error_gap, relative_runtime_checkpoints)
    error_gap_list = [f"error_gap_df{i+1}" for i in range(int(number_of_seeds))] # list of error gap columns

    print(number_of_seeds)
    
    # create new column and store average error from different columns with the same index
    
    prefinal_df["error_gap_stat_max"] = prefinal_df[error_gap_list].max(axis=1)

    return prefinal_df

if __name__ == "__main__":

    stop_criterion_value = 10

    # stats output filepath

    path_to_write_sing_sol_stats = os.path.join(os.getcwd(), "stats_output")

    ### Visualization

    # plot multiple datasets on the same plot

    C1_2_1_FIXDOM_BKS_20K = 6905.0115000000005

    C1_2_1_VARDOM_BKS_20K = 4779.2603

    datasets = [generate_resultdata("test_input/c1_2_1.pkl", C1_2_1_FIXDOM_BKS_20K)]

    for i, result_data in enumerate(datasets, start=1):
        runtime_plt_min = result_data[0]["relative_runtime_checkpoints_df1"].tolist()
        error_gap_plt_min = result_data[0]["error_gap_stat_min"].tolist()

        runtime_plt_mean = result_data[0]["relative_runtime_checkpoints_df1"].tolist()
        error_gap_plt_mean = result_data[0]["error_gap_stat_avg"].tolist()

        runtime_plt_max = result_data[0]["relative_runtime_checkpoints_df1"].tolist()
        error_gap_plt_max = result_data[0]["error_gap_stat_max"].tolist()


    # plt.plot(runtime_plt, error_gap_plt, label=f'Graph {i}: {result_data[1]}')
    plt.plot(runtime_plt_max, error_gap_plt_max, color = "blue", label=f'Graph {i}: {result_data[1]} ' + "$\it max $")
    plt.plot(runtime_plt_mean, error_gap_plt_mean, color = "grey", linestyle = "dotted", label=f'Graph {i}: {result_data[1]} ' + "$\it mean $")
    plt.plot(runtime_plt_min, error_gap_plt_min, color = "blue", label=f'Graph {i}: {result_data[1]} ' + "$\it min $")

    plt.xlabel("Relative Runtime")
    plt.ylabel("Error Gap (%), logarithmic scale")
    plt.title("Relative Runtime vs Error Gap (%)")

    # Plot: vertical lines for runtime checkpoints

    for i in range(0, 6):
        plt.axvline(x=i * 10 * 2, color='r', linestyle='--', alpha=0.5)

    ## Logarithmic scale for y-axis

    # Customize the y-axis ticks for a proper logarithmic scale

    plt.yscale("log")

    ax = plt.gca()
    ax.yaxis.set_major_locator(LogLocator(base=10.0, numticks=10))
    ax.yaxis.set_minor_locator(LogLocator(base=10.0, subs=(2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0), numticks=100))
    ax.yaxis.set_major_formatter(LogFormatter(base=10.0, labelOnlyBase=False))

    # Add minor ticks with a custom formatter
    def custom_log_formatter(x, pos):
        if x >= 10 and x in [10**i for i in range(1, 4)] + [10**i * j for i in range(1, 4) for j in range(2, 10)]:
            return f'{x:g}'
        else:
            return ''

    ax.yaxis.set_minor_formatter(plt.FuncFormatter(custom_log_formatter))

    # Axis gridlines (major/minor)

    ax.grid(which='major', linestyle='-', linewidth='0.1', color='black')
    ax.grid(which='minor', linestyle=':', linewidth='0.1', color='gray')

    # Add legend and save plot

    plt.legend(loc='upper right')
    plt.figtext(0.99, 0.01, f'T = {stop_criterion_value}', horizontalalignment='right') 
    plt.savefig("test_plots/error_gap_vs_runtime_c.png", dpi=1200) # TODO determin adequate dpi for better resolution
    plt.show()

# TODO cumulate iterations after each second to allow for multi-seed and multi-instance comparison (normative standard)
# TODO better input for multiple datasets (e.g. list of filepaths, list of bks, list of seeds)
# TODO formatting of plot axis scales (font size, tick labels, etc.)
# TODO generate insights

# TODO: vertical lines/axis gridlines; background image (Lukas code snippets)

#TODO: fix environment values to be omitted from the documentation
#TODO: fix docstring format to properly display arguments and return values
#TODO: fix logo to be displayed in the documentation, url instead of local path & beautify index.html
#TODO: host documentation on gitlab pages and configure access
